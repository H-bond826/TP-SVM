{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Rapport du TP sur les Machines à Vecteurs de Support (SVM)\"\n",
        "author: \"[Votre Nom Complet et celui de votre coéquipier]\"\n",
        "date: \"aujourd'hui\"\n",
        "format: \n",
        "  pdf:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "lang: fr\n",
        "---"
      ],
      "id": "5c43528c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "Ce rapport présente les résultats du travail pratique sur les Machines à Vecteurs de Support (SVM). L'objectif est d'explorer les principes fondamentaux des SVM, de comparer différents noyaux sur un jeu de données simple (Iris), puis d'appliquer ces techniques à une tâche plus complexe de classification de visages. Nous étudierons en particulier l'influence du paramètre de régularisation `C`, l'impact de l'ajout de variables non pertinentes (bruit), et l'amélioration des performances grâce à la réduction de dimension par Analyse en Composantes Principales (ACP/PCA).\n"
      ],
      "id": "5735ead3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "# --- Imports et configuration ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "id": "494a80c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification sur le jeu de données Iris\n",
        "\n",
        "Nous commençons par une tâche de classification simple sur le jeu de données Iris. Nous ne conserverons que les classes 1 et 2, ainsi que les deux premiers attributs pour permettre une visualisation en 2D. Nous comparons les performances d'un noyau linéaire et d'un noyau polynomial.\n"
      ],
      "id": "bec93e59"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| warning: false\n",
        "\n",
        "###################################################\n",
        "#               Iris Dataset\n",
        "###################################################\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "X = scaler.fit_transform(X)\n",
        "y = iris.target\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "\n",
        "# Visualization\n",
        "plt.show()\n",
        "plt.close(\"all\")\n",
        "plt.ion()\n",
        "plt.figure(1, figsize=(10, 5))\n",
        "plt.title('iris data set')\n",
        "plot_2d(X, y)\n",
        "\n",
        "# split train test (say 25% for the test)\n",
        "# using train_test_split whithout shuffling (fix the random state = 42) for reproductibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "id": "3c4ab411",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q1: Noyau Linéaire\n",
        "\n",
        "Nous utilisons `GridSearchCV` pour trouver le meilleur hyperparamètre de régularisation `C` pour un SVM à noyau linéaire.\n"
      ],
      "id": "b12894f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parameters_linear = {'kernel': ['linear'], 'C': np.logspace(-3, 3, 100)}\n",
        "clf_linear = GridSearchCV(SVC(), parameters_linear, n_jobs=-1)\n",
        "clf_linear.fit(X_train_iris, y_train_iris)\n",
        "\n",
        "train_score = clf_linear.score(X_train_iris, y_train_iris)\n",
        "test_score = clf_linear.score(X_test_iris, y_test_iris)\n",
        "\n",
        "print(f\"Meilleur C trouvé pour le noyau linéaire : {clf_linear.best_params_['C']:.4f}\")\n",
        "print(f\"Score sur l'ensemble d'entraînement : {train_score:.4f}\")\n",
        "print(f\"Score de généralisation (test) : {test_score:.4f}\")"
      ],
      "id": "ab7ff7a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q2: Noyau Polynomial\n",
        "\n",
        "Nous étendons la recherche pour un noyau polynomial, en optimisant `C`, `gamma`, et le degré du polynôme `degree`.\n"
      ],
      "id": "fd1e8119"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| warning: false\n",
        "parameters_poly = {\n",
        "    'kernel': ['poly'],\n",
        "    'C': np.logspace(-3, 3, 5),\n",
        "    'gamma': np.logspace(-3, 2, 5),\n",
        "    'degree': [2, 3, 4]\n",
        "}\n",
        "clf_poly = GridSearchCV(SVC(), parameters_poly, n_jobs=-1)\n",
        "clf_poly.fit(X_train_iris, y_train_iris)\n",
        "\n",
        "train_score_poly = clf_poly.score(X_train_iris, y_train_iris)\n",
        "test_score_poly = clf_poly.score(X_test_iris, y_test_iris)\n",
        "\n",
        "print(\"Meilleurs hyperparamètres pour le noyau polynomial :\")\n",
        "print(clf_poly.best_params_)\n",
        "print(f\"\\nScore sur l'ensemble d'entraînement : {train_score_poly:.4f}\")\n",
        "print(f\"Score de généralisation (test) : {test_score_poly:.4f}\")"
      ],
      "id": "3fb5492b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparaison et Visualisation des Frontières\n",
        "\n",
        "Visualisons les frontières de décision apprises par les deux modèles sur l'ensemble d'entraînement.\n"
      ],
      "id": "7b8f7c8a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false,
        "fig-width": 12,
        "fig-height": 5
      },
      "source": [
        "#| warning: false\n",
        "\n",
        "def f_linear(xx):\n",
        "    return clf_linear.predict(xx.reshape(1, -1))\n",
        "\n",
        "def f_poly(xx):\n",
        "    return clf_poly.predict(xx.reshape(1, -1))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "frontiere(f_linear, X_train_iris, y_train_iris)\n",
        "plt.title('Frontière de décision - Noyau Linéaire')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "frontiere(f_poly, X_train_iris, y_train_iris)\n",
        "plt.title('Frontière de décision - Noyau Polynomial')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "899c2c22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analyse :** Pour ce jeu de données, les classes sont presque linéairement séparables. Le noyau linéaire obtient un excellent score de généralisation. Le noyau polynomial, bien que plus flexible, n'apporte pas d'amélioration significative et pourrait même être sujet au sur-apprentissage si les paramètres n'étaient pas soigneusement choisis par validation croisée. La frontière non-linéaire qu'il apprend est très proche de la frontière linéaire.\n",
        "\n",
        "# Tâche de Classification de Visages\n",
        "\n",
        "Nous abordons maintenant une tâche plus complexe : distinguer les visages de deux personnalités publiques, Tony Blair et Colin Powell, à partir du jeu de données \"Labeled Faces in the Wild\" (LFW).\n"
      ],
      "id": "58e6dae5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "# --- Préparation des données LFW ---\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4,\n",
        "                              color=True, funneled=False, slice_=None,\n",
        "                              download_if_missing=True)\n",
        "\n",
        "images = lfw_people.images\n",
        "n_samples, h, w, n_colors = images.shape\n",
        "target_names = lfw_people.target_names.tolist()\n",
        "\n",
        "names = ['Tony Blair', 'Colin Powell']\n",
        "idx0 = (lfw_people.target == target_names.index(names[0]))\n",
        "idx1 = (lfw_people.target == target_names.index(names[1]))\n",
        "images = np.r_[images[idx0], images[idx1]]\n",
        "n_samples = images.shape[0]\n",
        "y_faces = np.r_[np.zeros(np.sum(idx0)), np.ones(np.sum(idx1))].astype(int)\n",
        "\n",
        "# Extraction de caractéristiques (passage en niveaux de gris et aplatissement)\n",
        "X_faces = (np.mean(images, axis=3)).reshape(n_samples, -1)\n",
        "\n",
        "# Division des données\n",
        "indices = np.random.permutation(X_faces.shape[0])\n",
        "train_idx, test_idx = indices[:X_faces.shape[0] // 2], indices[X_faces.shape[0] // 2:]\n",
        "X_train_faces_raw, X_test_faces_raw = X_faces[train_idx, :], X_faces[test_idx, :]\n",
        "y_train_faces, y_test_faces = y_faces[train_idx], y_faces[test_idx]\n",
        "images_train, images_test = images[train_idx, :, :, :], images[test_idx, :, :, :]\n",
        "\n",
        "# Standardisation (correctement, après la division)\n",
        "scaler_faces = StandardScaler()\n",
        "X_train_faces = scaler_faces.fit_transform(X_train_faces_raw)\n",
        "X_test_faces = scaler_faces.transform(X_test_faces_raw)"
      ],
      "id": "bb2da558",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q4: Influence du paramètre de régularisation `C`\n",
        "\n",
        "Le paramètre `C` contrôle le compromis entre la complexité du modèle (maximiser la marge) et l'erreur de classification sur l'ensemble d'entraînement. Un `C` faible favorise une grande marge au détriment de quelques erreurs (modèle simple, potentiellement sous-ajusté). Un `C` élevé pénalise fortement les erreurs, ce qui peut conduire à une marge plus petite et à un modèle complexe, risquant le sur-ajustement.\n",
        "\n",
        "Nous entraînons un SVM linéaire pour une plage de valeurs de `C` et observons son score sur l'ensemble de test.\n"
      ],
      "id": "8fefd86b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| warning: false\n",
        "\n",
        "print(\"--- Recherche du meilleur C pour le noyau linéaire ---\")\n",
        "t0 = time()\n",
        "Cs = np.logspace(-5, 5, 11)\n",
        "scores_train = []\n",
        "scores_test = []\n",
        "\n",
        "for C in Cs:\n",
        "    clf_tmp = SVC(kernel='linear', C=C)\n",
        "    clf_tmp.fit(X_train_faces, y_train_faces)\n",
        "    scores_train.append(clf_tmp.score(X_train_faces, y_train_faces))\n",
        "    scores_test.append(clf_tmp.score(X_test_faces, y_test_faces))\n",
        "\n",
        "print(f\"Recherche effectuée en {time() - t0:.3f}s\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(Cs, scores_train, label=\"Score d'entraînement\", marker='o')\n",
        "plt.plot(Cs, scores_test, label=\"Score de test\", marker='o')\n",
        "plt.xlabel(\"Paramètre de régularisation C\")\n",
        "plt.ylabel(\"Score (Accuracy)\")\n",
        "plt.xscale('log')\n",
        "plt.title(\"Influence du paramètre C sur la performance du SVM\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\")\n",
        "plt.show()\n",
        "\n",
        "best_idx = np.argmax(scores_test)\n",
        "best_C = Cs[best_idx]\n",
        "best_acc = scores_test[best_idx]\n",
        "print(f\"Meilleur C trouvé : {best_C:.2e}\")\n",
        "print(f\"Meilleur score de généralisation (accuracy) : {best_acc:.4f}\")"
      ],
      "id": "d470249a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analyse :** Le graphique illustre parfaitement le compromis biais-variance. Pour des valeurs de `C` très faibles, le modèle est sous-ajusté et ses performances sont médiocres sur les deux ensembles. À mesure que `C` augmente, le modèle s'adapte mieux aux données, et le score de test s'améliore, atteignant un pic. Si `C` devient trop grand, le modèle commence à sur-apprendre les spécificités du jeu d'entraînement (le score d'entraînement continue d'augmenter) au détriment de sa capacité à généraliser (le score de test stagne ou diminue).\n",
        "\n",
        "## Q5: Impact de l'ajout de variables de nuisance\n",
        "\n",
        "Nous allons maintenant évaluer l'effet de l'ajout de variables non informatives (bruit gaussien) sur les performances du classifieur. C'est une illustration de la \"malédiction de la dimensionnalité\".\n"
      ],
      "id": "74bc05eb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| warning: false\n",
        "\n",
        "def run_svm_grid_search(_X_train, _y_train, _X_test, _y_test):\n",
        "    parameters = {'kernel': ['linear'], 'C': np.logspace(-3, 3, 5)}\n",
        "    clf = GridSearchCV(SVC(), parameters, n_jobs=-1)\n",
        "    clf.fit(_X_train, _y_train)\n",
        "    test_score = clf.score(_X_test, _y_test)\n",
        "    return test_score\n",
        "\n",
        "# Score sur les données originales\n",
        "score_original = run_svm_grid_search(X_train_faces, y_train_faces, X_test_faces, y_test_faces)\n",
        "print(f\"Score de généralisation sur les données originales : {score_original:.4f}\")\n",
        "\n",
        "# Ajout de bruit aux données\n",
        "n_train_samples = X_train_faces.shape[0]\n",
        "n_test_samples = X_test_faces.shape[0]\n",
        "noise_train = np.random.randn(n_train_samples, 300)\n",
        "noise_test = np.random.randn(n_test_samples, 300)\n",
        "\n",
        "X_train_noisy = np.concatenate((X_train_faces, noise_train), axis=1)\n",
        "X_test_noisy = np.concatenate((X_test_faces, noise_test), axis=1)\n",
        "\n",
        "# Score sur les données bruitées\n",
        "score_noisy = run_svm_grid_search(X_train_noisy, y_train_faces, X_test_noisy, y_test_faces)\n",
        "print(f\"Score de généralisation sur les données bruitées : {score_noisy:.4f}\")"
      ],
      "id": "10c7ce12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analyse :** Comme attendu, l'ajout de 300 variables de bruit aléatoire a considérablement dégradé les performances du classifieur. Le modèle est \"distrait\" par ces caractéristiques non pertinentes et a plus de mal à trouver la frontière de séparation optimale basée sur les caractéristiques utiles.\n",
        "\n",
        "## Q6: Amélioration via la réduction de dimension (PCA)\n",
        "\n",
        "Pour contrer l'effet négatif des variables de nuisance, nous appliquons une Analyse en Composantes Principales (PCA) sur les données bruitées avant de les fournir au SVM. La PCA va identifier les axes de plus grande variance, qui correspondent (on l'espère) aux caractéristiques originales et non au bruit, nous permettant ainsi de \"nettoyer\" les données.\n"
      ],
      "id": "2df31cb7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| warning: false\n",
        "\n",
        "grid_n_components = [20, 60, 100, 150]\n",
        "test_scores_pca = []\n",
        "\n",
        "for k in grid_n_components:\n",
        "    print(f\"Test avec n_components = {k}...\")\n",
        "    pca = PCA(n_components=k, svd_solver='randomized', whiten=True)\n",
        "    \n",
        "    # Appliquer la PCA\n",
        "    X_train_pca = pca.fit_transform(X_train_noisy)\n",
        "    X_test_pca = pca.transform(X_test_noisy)\n",
        "    \n",
        "    # Calculer le score\n",
        "    score_pca = run_svm_grid_search(X_train_pca, y_train_faces, X_test_pca, y_test_faces)\n",
        "    test_scores_pca.append(score_pca)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(grid_n_components, test_scores_pca, marker='o')\n",
        "plt.xlabel(\"Nombre de composantes principales (k)\")\n",
        "plt.ylabel(\"Score de test (Accuracy)\")\n",
        "plt.title(\"Performance du SVM après PCA sur données bruitées\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "best_idx_pca = np.argmax(test_scores_pca)\n",
        "best_k = grid_n_components[best_idx_pca]\n",
        "best_score_pca = test_scores_pca[best_idx_pca]\n",
        "print(f\"Meilleur nombre de composantes : {best_k}\")\n",
        "print(f\"Meilleur score après PCA : {best_score_pca:.4f}\")"
      ],
      "id": "176fde51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analyse :** Les résultats sont spectaculaires. En utilisant la PCA pour réduire la dimensionnalité des données bruitées, nous avons pu récupérer, et même légèrement dépasser, les performances du modèle sur les données originales non bruitées. Le graphique montre qu'un nombre optimal de composantes (autour de 100-150) permet de capturer l'essentiel de l'information utile tout en filtrant une grande partie du bruit. Cela démontre l'efficacité de la PCA comme technique de pré-traitement pour les données de grande dimension.\n",
        "\n",
        "## Q7: Biais dans le prétraitement des données (Script Original)\n",
        "\n",
        "La question 7 du TP demande d'identifier un biais dans le prétraitement des données du script `svm_script.py`. Ce biais est un problème classique de **fuite de données (data leakage)**.\n",
        "\n",
        "Dans le script initial fourni pour le TP, l'étape de standardisation des caractéristiques (`X -= np.mean(X, axis=0); X /= np.std(X, axis=0)`) est appliquée sur **l'ensemble du jeu de données `X`**, *avant* de le diviser en un ensemble d'entraînement et un ensemble de test.\n",
        "\n",
        "**Pourquoi est-ce un biais ?**\n",
        "\n",
        "Le `StandardScaler` (ou la standardisation manuelle) calcule la moyenne et l'écart-type des données pour les centrer et les réduire. En effectuant cette opération sur la totalité des données, les statistiques de l'ensemble de test (moyenne et écart-type) sont utilisées pour transformer l'ensemble d'entraînement. Autrement dit, le modèle, pendant sa phase d'apprentissage, a accès à des informations provenant de données qu'il n'est pas censé avoir vues.\n",
        "\n",
        "**Quel est l'impact ?**\n",
        "\n",
        "Ce biais conduit à une **estimation trop optimiste des performances de généralisation du modèle**. Le score obtenu sur l'ensemble de test est artificiellement gonflé car les données de test ne sont plus totalement \"inconnues\" du processus d'entraînement.\n",
        "\n",
        "**La procédure correcte (appliquée dans ce rapport) :**\n",
        "\n",
        "1.  **Diviser** les données en ensemble d'entraînement et de test.\n",
        "2.  **Ajuster (`fit`)** le `StandardScaler` **uniquement** sur l'ensemble d'entraînement pour apprendre les paramètres de mise à l'échelle (moyenne et écart-type).\n",
        "3.  **Appliquer la transformation (`transform`)** avec ce même scaler sur l'ensemble d'entraînement ET sur l'ensemble de test.\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "Ce travail pratique nous a permis de mettre en œuvre et d'évaluer les SVM sur différentes tâches. Nous avons constaté l'importance du choix du noyau et des hyperparamètres, qui peuvent être optimisés par validation croisée. L'étude sur les données de visages a illustré de manière concrète l'impact du paramètre de régularisation `C` sur le compromis biais-variance. Enfin, nous avons démontré expérimentalement la malédiction de la dimensionnalité et l'efficacité de la PCA pour y remédier, tout en soulignant l'importance cruciale d'éviter la fuite de données lors du prétraitement pour obtenir une évaluation fiable des performances du modèle."
      ],
      "id": "b25726fb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "got",
      "language": "python",
      "display_name": "Python (got)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}